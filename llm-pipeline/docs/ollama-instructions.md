# ðŸ§  How to Install and Run Ollama (`mistral`) on Ubuntu, macOS, and Windows

## ðŸ“¦ Prerequisite: What is Ollama?
Ollama lets you run large language models (like Mistral) locally on your machine with simple commands.

---

## ðŸ§ Ubuntu

### âœ… Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

> **Note**: This installs Ollama to `/usr/local/bin/ollama`.

### â–¶ï¸ Run Mistral

```bash
ollama run mistral
```

### â–¶ï¸ Or Start Ollama Server

```bash
ollama serve
```

---

## ðŸŽ macOS (Intel & Apple Silicon)

### âœ… Install Ollama

Use Homebrew:

```bash
brew install ollama
```

Or use the official installer:

- Download from: [https://ollama.com/download](https://ollama.com/download)

### â–¶ï¸ Run Mistral

```bash
ollama run mistral
```

### â–¶ï¸ Or Start Ollama Server

```bash
ollama serve
```

---

## ðŸªŸ Windows (via WSL or Native)

> **Note:** As of now, native Windows support is limited. The recommended method is **using WSL (Windows Subsystem for Linux)**.

### âœ… Install WSL (if not already installed)

```powershell
wsl --install
```

Then open your WSL terminal (Ubuntu), and follow the **Ubuntu** installation steps above.

### â–¶ï¸ Run Mistral

```bash
ollama run mistral
```

### â–¶ï¸ Or Start Ollama Server

```bash
ollama serve
```

> **Native Windows version:** Check [https://ollama.com](https://ollama.com) for updates as native support evolves.

---

## âœ… Verification

Once installed, you can verify everything works by running:

```bash
ollama list
```

You should see Mistral downloaded or listed after the first run.

---

